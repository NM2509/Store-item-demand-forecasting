{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Time\n",
    "from datetime import datetime\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Other models\n",
    "import xgboost as xgb\n",
    "\n",
    "# Conversions\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "sns.set_style('darkgrid')\n",
    "pd.set_option('display.precision', 2)\n",
    "plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('/walmart-recruiting-store-sales-forecasting/features.csv')\n",
    "stores = pd.read_csv('/walmart-recruiting-store-sales-forecasting/stores.csv')\n",
    "dataset = pd.read_csv('/walmart-recruiting-store-sales-forecasting/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in stores.columns:\n",
    "    print(column, stores[column].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in stores.columns:\n",
    "    print(column, stores[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores['Type'].value_counts()\n",
    "# Imbalanced data with respect to stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't seem to have outliers with respect to size\n",
    "stores['Size'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA of features - to combine later in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Unemployment'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in features.columns:\n",
    "    print(column, features[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['MarkDown1'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_reductions = ['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']\n",
    "\n",
    "for element in price_reductions:\n",
    "    print(features[features['IsHoliday'] == True][element].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(features['Date'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataset.columns:\n",
    "    print(column, dataset[column].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values\n",
    "for column in dataset.columns:\n",
    "    print(column, dataset[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['Store'].unique())\n",
    "print(dataset['Dept'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = set(type(x) for x in dataset['Date'])\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = set(type(x) for x in dataset['Weekly_Sales'])\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(dataset['Weekly_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The upper boundary is fine\n",
    "np.sort(dataset['Weekly_Sales'])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to exclude negative numbers\n",
    "np.sort(dataset['Weekly_Sales'])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['Weekly_Sales'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[dataset['Weekly_Sales'] == 0])\n",
    "print(len(dataset[dataset['Weekly_Sales'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Date'] = dataset['Date'].apply(lambda _: datetime.strptime(_,\"%Y-%m-%d\"))\n",
    "dataset['year'] = dataset['Date'].apply(lambda _: _.year)\n",
    "dataset['month'] = dataset['Date'].apply(lambda _: _.month)\n",
    "dataset['day_of_month'] = dataset['Date'].apply(lambda _: _.day)\n",
    "dataset['weekday'] = dataset['Date'].apply(lambda _: _.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['year','month','day_of_month','weekday']\n",
    "\n",
    "for column in columns:\n",
    "    print(column, np.sort(dataset[column].unique()))\n",
    "\n",
    "# It seems like we only measure sales every Thursday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual representation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see a log-normal trend\n",
    "plot_data_2010 = dataset[dataset['year'] == 2010]\n",
    "plot_data_2011 = dataset[dataset['year'] == 2011]\n",
    "plot_data_2012 = dataset[dataset['year'] == 2012]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (20,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.histplot(data = plot_data_2010, x = 'Weekly_Sales', bins = 100)\n",
    "plt.title('Year 2010 - Sales')\n",
    "plt.xlim(0, 100000)\n",
    "plt.xlabel('Weekly_Sales')\n",
    "plt.subplot(1,3,2)\n",
    "sns.histplot(data = plot_data_2011, x = 'Weekly_Sales', bins = 100)\n",
    "plt.title('Year 2011 - Sales')\n",
    "plt.xlim(0, 100000)\n",
    "plt.xlabel('Weekly_Sales')\n",
    "plt.subplot(1,3,3)\n",
    "sns.histplot(data = plot_data_2012, x = 'Weekly_Sales', bins = 100)\n",
    "plt.title('Year 2012 - Sales')\n",
    "plt.xlim(0, 100000)\n",
    "plt.xlabel('Weekly_Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes sense that there is more sales just before Christmas\n",
    "month_sls = dataset.groupby('month')['Weekly_Sales'].mean()\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.barplot(x = month_sls.index, y = month_sls.values, color = 'lightblue')\n",
    "plt.title('Average Weekly Sales per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes sense that there is not much explanatory power in the day of the month\n",
    "weekday_sls = dataset.groupby('day_of_month')['Weekly_Sales'].mean()\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.barplot(x = weekday_sls.index, y = weekday_sls.values, color = 'lightblue')\n",
    "plt.title('Average Weekly Sales per Weekday')\n",
    "plt.xlabel('Weekday')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(dataset.groupby(['month', 'year'])['Weekly_Sales'].sum().unstack(), cmap='Blues')\n",
    "plt.title('Heatmap of sales per month and year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding type and size\n",
    "data = pd.merge(stores, dataset, on = 'Store', how = 'left')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding features\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "features['Date'] = pd.to_datetime(features['Date'])\n",
    "data = pd.merge(data, features, on=['Store', 'Date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the two columsn identical?\n",
    "np.sum(data['IsHoliday_x'] == data['IsHoliday_y'])-len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('IsHoliday_y', axis = 1, inplace = True)\n",
    "data.rename(columns = {'IsHoliday_x':'IsHoliday'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekday is the same, so we can drop it\n",
    "data.drop('weekday', axis = 1, inplace = True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be using the model on the future data, we shouldn't take into account 'year' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['year','Date'], axis = 1, inplace = True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark model - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of missing values in each column\n",
    "for column in data.columns:\n",
    "    print(column, data[column].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a very simple model that will act as a lower benchmark\n",
    "X = data[['Store', 'Type','Size','Dept','IsHoliday','month','day_of_month','Temperature','Fuel_Price','CPI','Unemployment']].copy()\n",
    "y = data['Weekly_Sales'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "X = pd.get_dummies(X, columns = ['Store', 'Type','Dept','IsHoliday','month','day_of_month'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fitted = model.predict(X)\n",
    "plt.hist(y_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a log-transformation of the target variable because all output should be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 1 because we can't have 0 with log\n",
    "y_log = np.log(y + 1)\n",
    "model.fit(X, y_log)\n",
    "y_fitted_log = model.predict(X)\n",
    "y_fitted = np.exp(y_fitted_log) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_fitted, bins = 100)\n",
    "plt.xlim(-1000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted mean absolute error\n",
    "def wmae(y, y_pred, weights):\n",
    "    return np.sum(weights * np.abs(y - y_pred)) / np.sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = 5 if the week is a holiday week, 1 otherwise\n",
    "df = pd.DataFrame({'y_true': y, 'y_pred': y_fitted, 'weights': np.where(data['IsHoliday'] == True, 5, 1)}) \n",
    "#df = df[df['y_true'] != 0]\n",
    "\n",
    "y_true = df['y_true']\n",
    "y_pred = df['y_pred']\n",
    "weights = df['weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmae_error = wmae(y_true, y_pred, weights).round(2)\n",
    "print(\"LR WMAE: {:,.0f}\".format(wmae_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_error = mean_squared_error(y_true, y_pred)\n",
    "print(\"LR MSE: {:,.0f}\".format(lr_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complex models - XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weight to the data\n",
    "data['weights'] = np.where(data['IsHoliday'] == True, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "X.drop(['Weekly_Sales'], axis=1, inplace=True)\n",
    "y = data['Weekly_Sales']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not create any interaction terms because the model should be able to capture those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns = ['Store','Type','Dept','IsHoliday','month','day_of_month'], drop_first = True)\n",
    "X_val = pd.get_dummies(X_val, columns = ['Store','Type','Dept','IsHoliday','month','day_of_month'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use higher depth than 2, because there are interdependencies in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_train_boosting same as X_train but without weights\n",
    "X_train_boosting = X_train.copy()\n",
    "X_train_boosting.drop('weights', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With log - because XGBoosting fits any new model on the pseudo residuals of the previous model, and hence it can result in negative value output\n",
    "y_train_log = np.log(y_train + 1)\n",
    "\n",
    "param_grid = {'n_estimators': [100, 300, 500, 900],\n",
    "              'learning_rate': [0.1, 0.5, 0.7, 0.9],\n",
    "              'max_depth': [2, 3, 5, 7, 9]}\n",
    "\n",
    "model = xgb.XGBRegressor(seed = 42, \n",
    "                         booster = 'gbtree',\n",
    "                         objective = 'reg:squarederror',\n",
    "                         tree_method = 'hist')\n",
    "\n",
    "grid_search = GridSearchCV(estimator= model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train_boosting, y_train_log)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With log\n",
    "y_train_log = np.log(y_train + 1)\n",
    "\n",
    "model = xgb.XGBRegressor(seed=42, \n",
    "                         booster = 'gbtree', \n",
    "                         objective = 'reg:squarederror', \n",
    "                         tree_method = 'hist',\n",
    "                         learning_rate = 0.5, \n",
    "                         n_estimators = 900,\n",
    "                         max_depth = 7)\n",
    "\n",
    "# drop weights for training\n",
    "model.fit(X_train_boosting, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_boosting = X_val.copy()\n",
    "X_val_boosting.drop('weights', axis = 1, inplace = True)\n",
    "\n",
    "y_log_fitted = model.predict(X_val_boosting)\n",
    "y_fitted = np.exp(y_log_fitted) - 1\n",
    "\n",
    "xgb_error = mean_squared_error(y_val, y_fitted)\n",
    "print(\"XGBoost MSE: {:,.0f}\".format(xgb_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_true': y_val, 'y_pred': y_fitted, 'weights': X_val['weights']}) \n",
    "\n",
    "y_true = df['y_true']\n",
    "y_pred = df['y_pred']\n",
    "weights = df['weights']\n",
    "\n",
    "wmae_error = wmae(y_true, y_pred, weights).round(2)\n",
    "print(\"XGBoosting WMAE: {:,.0f}\".format(wmae_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/walmart-recruiting-store-sales-forecasting/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Date'] = test['Date'].apply(lambda _: datetime.strptime(_,\"%Y-%m-%d\"))\n",
    "test['month'] = test['Date'].apply(lambda _: _.month)\n",
    "test['day_of_month'] = test['Date'].apply(lambda _: _.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.merge(stores, test, on = 'Store', how = 'left')\n",
    "\n",
    "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
    "features['Date'] = pd.to_datetime(features['Date'])\n",
    "\n",
    "test_data = pd.merge(test_data, features, on=['Store', 'Date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(['Date','IsHoliday_y'], axis = 1, inplace = True)\n",
    "test_data.rename(columns = {'IsHoliday_x':'IsHoliday'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.get_dummies(test_data, columns = ['Store','Type','Dept','IsHoliday','month','day_of_month'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns that are present in X_val but not in test\n",
    "columns_to_add = []\n",
    "for column in X_val_boosting.columns:\n",
    "    if column not in test_data.columns:\n",
    "        print(column)\n",
    "        columns_to_add.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_add:\n",
    "    test_data[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_boosting.columns) == len(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fitted_log = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fitted = np.exp(y_fitted_log) - 1\n",
    "np.sort(y_fitted)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'y_fitted': y_fitted})\n",
    "df[df['y_fitted'] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fitted = df['y_fitted']\n",
    "np.sort(y_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-download test\n",
    "test = pd.read_csv('/walmart-recruiting-store-sales-forecasting/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add y_fitted column\n",
    "test['Id'] = test['Store'].astype(str) + '_' + test['Dept'].astype(str) + '_' + test['Date'].astype(str)\n",
    "test['Weekly_Sales'] = y_fitted\n",
    "test.drop(['Store','Dept','Date','IsHoliday'], axis = 1, inplace = True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "test.to_csv('to_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
